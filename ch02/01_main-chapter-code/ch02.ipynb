{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aa40e3-5109-433f-9153-f5770531fe94",
   "metadata": {},
   "source": [
    "# Chương 2: Làm việc với dữ liệu văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5d2c0-cba8-404e-9bf3-71a218cae3cf",
   "metadata": {},
   "source": [
    "Cài đặt thư viện\n",
    "- Pytorch: https://pytorch.org/get-started/locally/\n",
    "- `pip install tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0+cu124\n",
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b2922-594d-4ff9-bd82-04f1ebdf41f5",
   "metadata": {},
   "source": [
    "<img src=\"https://images.viblo.asia/ca53ac05-df27-4ae9-86f7-f8441fd5c8b5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417139b-2357-44d2-bd67-23f5d7f52ae7",
   "metadata": {},
   "source": [
    "## 2.1 Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6816ae-e927-43a9-b4dd-e47a9b0e1cf6",
   "metadata": {},
   "source": [
    "Các mô hình ngôn ngữ như LLMs không thể xử lý trực tiếp dữ liệu văn bản, thay vào đó cần phải **Toán học hóa** chúng bằng cách chuyển đổi thành các vector (dạng số học) để mô hình có thể hiểu và xử lý thông tin.\n",
    "\n",
    "> Mọi thứ đều là số - **Pythagoras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf0df1",
   "metadata": {},
   "source": [
    "Khái niệm chuyển đổi dữ diệu thành các vector gọi là **embeddings**. Không chỉ có dữ liệu văn bản, mà các kiểu dữ liệu khác như âm thanh, video cũng được chuyển sang dạng vector trước khi xử lý."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08d16f-f237-4166-bf89-0e9fe703e7b4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/02.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2ea5a",
   "metadata": {},
   "source": [
    "Một trong những thuật toán phổ biến dùng trong việc chuyển đổi văn bản được nhóm nghiên cứu của Google công bố vào năm 2013 có tên là **Word2Vec**.\n",
    "\n",
    "**Word2Vec** dự đoán ngữ cảnh của một từ dựa trên từ mục tiêu hoặc ngược lại. Ý tưởng chính đằng sau Word2Vec là các từ xuất hiện trong những ngữ cảnh tương tự có xu hướng mang ý nghĩa giống nhau.\n",
    "\n",
    "Ví dụ ta có các câu sau trong tập dữ liệu huấn luyện:\n",
    "\n",
    "1. \"Nhà vua trị vì đất nước của ông.\"\n",
    "2. \"Nữ hoàng cai trị vương quốc của bà.\"\n",
    "\n",
    "**Word2Vec** học được rằng \"vua\" và \"nữ hoàng\" thường xuất hiện trong ngữ cảnh tương tự. Kiểm tra khoảng cách giữa 2 vector cũng sẽ thấy rất gần nhau.\n",
    "\n",
    "Do đó, khi được chiếu vào không gian hai chiều để trực quan hóa, các từ có ý nghĩa tương tự sẽ được nhóm lại với nhau, như minh họa trong hình dưới đây."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b80160-1f10-4aad-a85e-9c79444de9e6",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/03.webp\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ef6d4",
   "metadata": {},
   "source": [
    "Trong thực tiễn, các từ sẽ được biểu diễn ở số chiều lớn hơn nhiều so với hình học không gian cổ điển. 2 đến 3 chiều là không đủ để biểu diễn, phân biệt hàm trăm nghìn, hàng triệu hoặc từ trong các bộ dữ liệu văn bản.\n",
    "\n",
    "| Phiên bản | Số chiều vector embeddings |\n",
    "| -------- | -------- |\n",
    "| GPT-2     | 768     | \n",
    "| GPT-2 Large     | 1280     | \n",
    "| GPT-2 XL    | 1600   | \n",
    "| GPT-3 (175B)     | 12288  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8246a70",
   "metadata": {},
   "source": [
    "Tuy nhiên, các LLMs như **GPT** sẽ không dùng **Word2Vec** mà có cách riêng để tạo **embledding**. Do phương pháp này bộc lộ một số hạn chế sau :\n",
    "- Nếu một từ có nhiều nghĩa khác nhau, Word2Vec vẫn chỉ tạo một vector duy nhất.\n",
    "- Chưa xử lý tốt các văn bản dài: Word2Vec chỉ dựa vào ngữ cảnh gần của từ mà không xem xét ngữ cảnh lớn hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbb984-8d23-40c5-bbfa-c3c379e7eec3",
   "metadata": {},
   "source": [
    "## 2.2 Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c90731-7dc9-4cd3-8c4a-488e33b48e80",
   "metadata": {},
   "source": [
    "**Tokenizing text** (hay tokenization) là quá trình chuyển đổi một chuỗi văn bản thành các đơn vị nhỏ hơn, gọi là **tokens**. Các tokens có thể là một từ, cụm từ, hoặc một ký hiệu, tùy thuộc vào ngữ cảnh và mục đích của việc xử lý văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a325eb",
   "metadata": {},
   "source": [
    "Dưới đây là hình minh họa các bước xử lý để tạo ra **token embeddings** của họ nhà GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09872fdb-9d4e-40c4-949d-52a01a43ec4b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/04.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cceaa18-833d-46b6-b211-b20c53902805",
   "metadata": {},
   "source": [
    "- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict): File văn bản của một câu chuyện ngắn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f9d9b1-6d32-485a-825a-a95392a86d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a769e87-470a-48b9-8bdb-12841b416198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# Mở file và đọc nội dung\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b971a46-ac03-4368-88ae-3f20279e8f4e",
   "metadata": {},
   "source": [
    "Xây dựng các phiên bản tách văn bản thành các token từ đơn giản đến phức tạp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737dd5b0-9dbb-4a97-9ae4-3482c8c04be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text) # Tách chuỗi theo khoảng trắng\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea02489d-01f9-4247-b7dd-a0d63f62ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text) # Tách chuỗi theo dấu phẩy, dấu chấm và khoảng trắng\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8a6fb7-2e62-4a12-ad06-ccb04f25fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "# Bỏ bớt các phần tử rỗng hoặc chỉ có khoảng trắng\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3a9467-04b4-49d9-96c5-b8042bcf8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text) # Tách chuỗi theo dấu câu và khoảng trắng\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe9330-b587-4262-be9f-497a84ec0e8a",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/05.webp\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c567caa-8ff5-49a8-a5cc-d365b0a78a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện trên file the-verdict.txt\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a19e1a-5105-4ddb-812a-b7d3117eab95",
   "metadata": {},
   "source": [
    "- Tính tổng số token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35db7b5e-510b-4c45-995f-f5ad64a8e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231",
   "metadata": {},
   "source": [
    "## 2.3 Chuyển đổi tokens sang token IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5204973-f414-4c0d-87b0-cfec1f06e6ff",
   "metadata": {},
   "source": [
    "Sau khi đã tách văn bản thành các **tokens**, bước tiếp theo sẽ là mã hóa các tokens thành các token IDs. Mỗi token sẽ ứng với một giá trị khác nhau được định nghĩa trong tệp từ vựng (**Vocabulary**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b041d-f739-43b8-bd81-0443ae3a7f8d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/06.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5973794-7002-4202-8b12-0900cd779720",
   "metadata": {},
   "source": [
    "- Từ các tokens, xây dựng tệp từ vựng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fdf0533-5ab6-42a5-83fa-a3b045de6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d00d96-881f-4691-bb03-84fec2a75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)} # Mỗi token ứng với một số nguyên theo thứ tự tăng dần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3",
   "metadata": {},
   "source": [
    "- Xem 50 từ đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c5de4a-aa4e-4aec-b532-10bb364039d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc314-351b-476a-9459-0ec9ddc29b19",
   "metadata": {},
   "source": [
    "- Hình minh hoạ với 1 tệp từ vựng nhỏ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67407a9f-0202-4e7c-9ed7-1b3154191ebc",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/07.webp?123\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e569647-2589-4c9d-9a5c-aef1c88a0a9a",
   "metadata": {},
   "source": [
    "- Các logic đã xây dựng viết vào một class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f531bf46-7c25-4ef8-bff8-0d27518676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7",
   "metadata": {},
   "source": [
    "- Hàm `encode`: Chuyển token -> tokenId\n",
    "- The `decode`: Chuyển tokenId -> token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21d347-ec03-4823-b3d4-9d686e495617",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/08.webp?123\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647364ec-7995-4654-9b4a-7607ccf5f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01d8c8fb-432d-4a49-b332-99f23b233746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f6aa8b-9827-412e-9035-e827296ab0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b821ef8-4d53-43b6-a2b2-aef808c343c7",
   "metadata": {},
   "source": [
    "## 2.4 Thêm ký tự đặc biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d6d15-a3e2-44e0-b384-bb37f17cf443",
   "metadata": {},
   "source": [
    "- Các từ không có trong từ điển thì thay bằng `<|unk|>`\n",
    "- `|endoftext|` để báo hiệu kết thúc văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7fc96c-e1fd-44fb-b7f5-229d7c7922a4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/09.webp?123\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336b43b-7173-49e7-bd80-527ad4efb271",
   "metadata": {},
   "source": [
    "- Minh hoạ việc sử dụng `<|endoftext|>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52442951-752c-4855-9752-b121a17fef55",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/10.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5767eff-440c-4de1-9289-f789349d6b85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizerV1(vocab)\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea. Is this-- a test?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mencode(text)\n",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m      9\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53ee0c-fe2b-4cd8-a946-5471f7651acf",
   "metadata": {},
   "source": [
    "- Ở trên lỗi vì từ \"Hello\" trong có trong `vocab`\n",
    "- Để xử lý TH này, thêm ký tự đặc biệt `<|unk|>` vào `vocab`. Khi đó \"Hello\" => `<|unk|>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce9df29c-6c5b-43f1-8c1a-c7f7b79db78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c3143b-e860-4d3b-a22a-de22b547a6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50e51bb1-ae05-4aa8-a9ff-455b65ed1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1daa2b0-6e75-412b-ab53-1f6fb7b4d453",
   "metadata": {},
   "source": [
    "- Sửa hàm `encode` để xử lý `<unk>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "948861c5-3f30-4712-a234-725f20d26f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa728dd1-9d35-4ac7-938f-d411d73083f6",
   "metadata": {},
   "source": [
    "Let's try to tokenize text with the modified tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133c502-18ac-4412-9f43-01caf4efa3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ed395fe-dc1b-4ed2-b85b-457cc35aab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "059367f9-7a60-4c0d-8a00-7c4c766d0ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ba34b-170f-4e71-939b-77aabb776f14",
   "metadata": {},
   "source": [
    "## 2.5 BytePair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aaef72",
   "metadata": {},
   "source": [
    "Phương pháp tạo ra tệp từ vựng (Vocabulary) như trên sẽ bộc lộ hạn chế khi làm việc với số lượng từ rất lớn. Trong thực tiễn, các mô hình GPT hay Llama sử dụng một thuật toán phức tạp hơn gọi là **Byte pair encoding (BPE)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309494c-79cf-4a2d-bc28-a94d602f050e",
   "metadata": {},
   "source": [
    "**BPE** hoạt động dựa trên việc hợp nhất các cặp ký tự hoặc âm tiết phổ biến trong văn bản để tạo thành tệp từ vựng. Một ví dụ đơn giản như sau:\n",
    "\n",
    "### Bước 1:\n",
    "Một văn bản dài chỉ được tạo thành bởi 5 từ sau `\"hug pug pun bun hugs\"`\n",
    "\n",
    "### Bước 2:\n",
    "Từ vựng cơ sở là các chữ cái tạo nên văn bản, khi này **Tệp từ vựng** là `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]`\n",
    "\n",
    "### Bước 3:\n",
    "Đếm tần số xuất hiện của các từ `(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)`\n",
    "\n",
    "### Bước 4:\n",
    "Lại tách từng từ thành các ký tự như sau:\n",
    "\n",
    "`(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)`\n",
    "\n",
    "### Bước 5:\n",
    "Cặp **ug** có tần suất nhiều nhất (20 lần). Ta tiến hành hợp nhất `(\"u\", \"g\") -> \"ug\"` \n",
    "\n",
    "**Tệp từ vựng** mới là: `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\"]`\n",
    "\n",
    "**Danh sách các tokens**: `(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)`\n",
    "\n",
    "### Bước 6:\n",
    "\n",
    "Lại xét cặp **un** (16 lần) nhiều nhất. Tiến hành hợp nhất `(\"u\", \"n\") -> \"un\"`\n",
    "\n",
    "**Tệp từ vựng** mới là: `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]`\n",
    "\n",
    "**Danh sách các tokens**: `(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)`\n",
    "\n",
    "Tiếp tục làm vậy cho đến khi chúng ta chạm đến kích thước tệp từ vựng mong muốn.\n",
    "\n",
    "\n",
    "> ChatGPT đang dùng tệp từ vựng gồm có **50257** tokens (https://openaipublic.blob.core.windows.net/gpt-2/encodings/main/encoder.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede1d41f-934b-4bf4-8184-54394a257a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48967a77-7d17-42bf-9e92-fc619d63a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ff2cd85-7cfb-4325-b390-219938589428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d26a48bb-f82e-41a8-a955-a1c9cf9d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2e7b4-6a22-42aa-8e4d-901f06378d4a",
   "metadata": {},
   "source": [
    "- BPE không dùng `<|unk|>` mà phân chia các từ chưa biết thành các từ nhỏ hơn và ký tự."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082d41f-33d7-4827-97d8-993d5a84bb3c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/11.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd7c0d-70f8-4386-a114-907e96c950b0",
   "metadata": {},
   "source": [
    "## 2.6 Cửa sổ trượt (sliding window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d9826-6384-462e-aa8a-a7c73cd6aad0",
   "metadata": {},
   "source": [
    "- Như đã biết, LLMs dựa vào các từ trước đó để sinh ra từ tiếp theo. Do đó, cần sắp xếp dữ liệu sao cho mô hình \"không nhìn thấy\" được các từ kế tiếp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb44f4-0c43-4a6a-9c2f-9cf31452354c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/12.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d5ade-fd1f-46c3-9e31-1426e315c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text)) # Số lượng token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd0657-5543-43ca-8011-2ae6bd0a5810",
   "metadata": {},
   "source": [
    "- Đối với mỗi đoạn văn bản, chúng ta cần 2 giá trị là `input` và `target`\n",
    "- Vì chúng ta muốn mô hình dự đoán từ tiếp theo, `target` dịch chuyển sang phải một vị trí so với `input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e84424a7-646d-45b6-99e3-80d15fb761f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfbff852-a92f-48c8-a46d-143a0f109f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d97b031e-ed55-409d-95f2-aeb38c6fe366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f57bd746-dcbf-4433-8e24-ee213a8c34a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c",
   "metadata": {},
   "source": [
    "Các mô hình ngôn ngữ lớn thường có giới hạn về kích thước ngữ cảnh (**context window**), tức là số lượng token mà mô hình có thể xử lý cùng một lúc.\n",
    "\n",
    "**Sliding Window** là một kỹ thuật cho phép chia nhỏ các chuỗi văn bản dài thành các đoạn ngắn hơn và xử lý chúng một cách tuần tự. Các đoạn ngắn hơn, mỗi đoạn có độ dài nhất định (window size).\n",
    "\n",
    "Hai đặc tính của **sliding window**:\n",
    "- **Context length**: Độ dài của mỗi đoạn sau khi được chia nhỏ.\n",
    "- **Stride**: Thông số thể hiện sự xê dịch giữa các đoạn với nhau.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/13.webp?123\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac652d-7b38-4843-9fbd-494cdc8ec12c",
   "metadata": {},
   "source": [
    "- Create dataset and dataloader that extract chunks from the input text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b41073-4c9f-46e2-a1bd-d38e4122b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize toàn bộ văn bản\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        # Sử dụng sliding window với độ dài max_length là tham số truyền vào\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5eb30ebe-97b3-43c5-9ff1-a97d621b3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # thư viện tiktoken của OpenAI, dùng kỹ thuật BPE\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df31d96c-6bfd-4564-a956-6192242d7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9226d00c-ad9a-4949-a6e4-9afccfc7214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10deb4bc-4de1-4d20-921e-4b1c7a0e1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006212f-de45-468d-bdee-5806216d1679",
   "metadata": {},
   "source": [
    "- Ảnh minh hoạ với 2 TH `stride = 1` và `stride = 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/14.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae6d45-f26e-4b83-9c7b-cff55ffa7d16",
   "metadata": {},
   "source": [
    "Như ảnh trên thì thấy dùng stride = 4 sẽ hạn chế việc trùng lặp nhiều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1916e7a6-f03d-4f09-91a6-d0bdbac5a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2fcda-2fda-4aa8-8bc8-de1e496f9db1",
   "metadata": {},
   "source": [
    "## 2.7 Tạo Token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85089aa-8671-4e5f-a2b3-ef252004ee4c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/15.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6304c-9474-4470-b85d-3991a49fa653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ có 4 token ids\n",
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da6344-2c71-4837-858d-dd120005ba05",
   "metadata": {},
   "source": [
    "### Ma trận embedding\n",
    "\n",
    "Ta có ma trận embedding $W \\in \\mathbb{R}^{V \\times d}$, trong đó:\n",
    "- **V** (số  cột):  Kích thước từ vựng (vocabulary size)\n",
    "- **d** (số hàng): Số chiều của embeddings, ví dụ: `d=768` trong GPT-2.\n",
    "\n",
    "token Id `X` sẽ được tham chiếu với hàng thứ `X + 1` trong ma trận embedding.\n",
    "\n",
    "Vậy câu hỏi đặt ra là lấy ra cái ma trận embedding này ở đâu ? Xin thưa là **ma trận embedding** được tạo ra bằng cách huấn luyện sử dụng các phương pháp khác như `one-hot encoding` hay mạng nơ-ron ... Chi tiết có lẽ chúng ta sẽ gặp nhau ở một bài viết khác nói riêng về chủ đề này 😄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb2cee-9aa6-4bb8-8977-c65661d16eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6 # V = 6\n",
    "output_dim =  3 # d = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim) # Ma trận embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff241f6-78eb-4e4a-a55f-5b2b6196d5b0",
   "metadata": {},
   "source": [
    "- Kích thước ma trận là 6x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a686eb61-e737-4351-8f1c-222913d47468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43600ba-f287-4746-8ddf-d0f71a9023ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3]))) # Chuyển tokenId = 3 thành token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50280ead-0363-44c8-8c35-bb885d92c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids)) # Chuyển 4 token ids ban đầu thành 4 token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97ced4-bd13-42b7-866a-4d699a17e155",
   "metadata": {},
   "source": [
    "Minh hoạ:\n",
    "- Ví dụ ta có tokenId 5. Ta tìm đến hàng thứ 6 của ma trận embedding => Đó là giá trị token embeddings của tokenId = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c2741-bf1b-4c60-b7fd-61409d556646",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/16.webp?123\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393d270-b950-4bc8-99ea-97d74f2ea0f6",
   "metadata": {},
   "source": [
    "## 2.8 Vị trí của từ trong câu (word positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24940068-1099-4698-bdc0-e798515e2902",
   "metadata": {},
   "source": [
    "Với đầu ra **token embeddings** ở phần trên, chúng ta đã có thể đưa vào mô hình để chạy.\n",
    "\n",
    "Tuy nhiên, chưa có cách nào phân biệt hai từ giống nhau nằm ở các vị trí khác nhau. Điều này ảnh hưởng rất lớn đến việc mô hình hiểu được ngữ nghĩa, cấu trúc trong câu vì thứ tự từ trong câu thay đổi có thể thay đổi ý nghĩa của toàn bộ câu.\n",
    "\n",
    "Ví dụ, câu `Con mèo đuổi theo con chuột` có ý nghĩa khác với `Con chuột đuổi theo con mèo`.\n",
    "\n",
    "Giải pháp ở đây là chúng ta sẽ thêm một **position embeddings** cộng với **token embeddings** để ra kết quả cuối cùng là **input embeddings**.\n",
    "\n",
    "Hiện này có 2 cách phổ biến để tính toán *position embeddings* là **Positional Encoding (PE)** và **Learnable Position Embeddings (LPE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b14a2-f3f3-490e-b513-f262dbcf94fa",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/17.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de37db-d54d-45c4-ab3e-88c0783ad2e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/18.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439c89f",
   "metadata": {},
   "source": [
    "Hiện này có 2 cách phổ biến để tính toán *position embeddings* là **Positional Encoding (PE)** và **Learnable Position Embeddings (LPE)**\n",
    "\n",
    "### Positional Encoding (PE)\n",
    "\n",
    "**Positional Encoding** được sử dụng trong **Transformer** và các mô hình đời đầu của GPT như GPT-2. Phương pháp này sử dùng 2 hàm lượng giác **sin và cos** để tính toán các vector vị trí.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "PE_{(pos, 2i)} &= \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right) \\\\\n",
    "\\\\\n",
    "PE_{(pos, 2i+1)} &= \\cos\\left(\\frac{pos}{10000^{2i/d}}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "hay\n",
    "\n",
    "$$\n",
    "PE_{(pos, k)} =\n",
    "\\begin{cases} \n",
    " \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right) & \\text{Nếu } k = 2i \\text{ với } 0 \\leq i < \\frac{d}{2}  \\\\\n",
    "\\cos\\left(\\frac{pos}{10000^{2i/d}}\\right) & \\text{Nếu } k = 2i + 1 \n",
    "\\text{ với } 0 \\leq i < \\frac{d}{2}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- **pos** là vị trí của từ trong câu (0 <= pos < L / 2 với **L** là độ dài của câu)\n",
    "- **d** là số chiều của embedding\n",
    "- **i** dùng để tính vị trí phần tử trong mỗi hàng\n",
    "\n",
    "|  Từ | pos | k = 0, i = 0 |k = 1,  i = 0 |k = 2,  i = 1 |k = 3,  i = 1 |\n",
    "| -------- | -------- | -------- | -------- | -------- | -------- |\n",
    "| I     | 0   | $PE_{(0, 0)}$ = sin(0) = 0     |  $PE_{(0, 1)}$ = cos(0) = 1|  $PE_{(0, 2)}$ = sin(0) = 0|  $PE_{(0, 3)}$ = cos(0) = 1|\n",
    "| am     | 1     |  $PE_{(1, 0)}$ = sin(1) = 0.84     | $PE_{(1, 1)}$ = cos(1) = 0.54| $PE_{(1, 2)}$ = sin(1/100) = 0.0099| $PE_{(1, 3)}$ = cos(1/100) = 0.99995|\n",
    "| a     | 2     |  $PE_{(2, 0)}$ = sin(2) = 0.91    | $PE_{(2, 1)}$ = cos(2) = -0.42 | $PE_{(2, 2)}$ = sin(2/100) = 0.019 | $PE_{(2, 3)}$ = cos(2/100) = 0.9998 |\n",
    "| Robot    | 3     |  $PE_{(3, 0)}$ = sin(3) = 0.14    |  $PE_{(3, 1)}$ = cos(3) = -0.99 |  $PE_{(3, 2)}$ = sin(3/100) = 0.029 |  $PE_{(3, 3)}$ = cos(3/100) = 0.99 |\n",
    "\n",
    "```python\n",
    "# postion embeddings\n",
    "tensor([[ 0, 1, 0, 1],\n",
    "        [ 0.84, 0.54, 0.0099, 0.99995],\n",
    "        [ 0.91, -0.42, 0.019, 0.9998],\n",
    "        [ 0.14, -0.99, 0.029, 0.99]\n",
    "])\n",
    "```\n",
    "\n",
    "### Learnable Position Embeddings (LPE)\n",
    "\n",
    "Giống như phương pháp tạo **token embeddings**, LPE cung cấp một ma trận vị trí kích thước **(L, d)**\n",
    "\n",
    "$$PE = W_{pos}$$\n",
    "- L là độ dài của chuỗi\n",
    "- d số chiều của embeddings\n",
    "\n",
    "Vị trí nào sẽ ứng với dòng đó trong ma trận khi chuyển đổi.\n",
    "\n",
    "## So sánh PE và LPE\n",
    "\n",
    "| | Positional Encoding (PE) | Learnable Position Embeddings (LPE) |\n",
    "| -------- | -------- | -------- |\n",
    "| Cách tính toán     | Dùng hàm lượng giác     | Sử dụng ma trận |\n",
    "| Huấn luyện được    | Không     | Có |\n",
    "| Bộ nhớ    | Ít tốn bộ nhớ     | Tốn nhiều bộ nhớ hơn |\n",
    "| Có thể tùy chỉnh    | Không     | Có |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f187f87-c1f8-4c2e-8050-350bbb972f55",
   "metadata": {},
   "source": [
    "Ví dụ với Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b9e344d-03a6-4f2c-b723-67b6a20c5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56a263-3d2e-4d91-98bf-d0b68d3c7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dùng sliding window để chia nhỏ\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84416b60-3707-4370-bcbc-da0b62f2b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7766ec38-30d0-4128-8c31-f49f063c43d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape) # Kích thước của ma trận embeddings\n",
    "\n",
    "# uncomment & execute the following line to see how the embeddings look like\n",
    "# print(token_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ae164-6f19-4e32-b9e5-76950fcf1c9f",
   "metadata": {},
   "source": [
    "- GPT-2 dùng Learnable Position Embeddings (LPE) nên cần tạo 1 ma trận `pos_embedding_layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc048e20-7ac8-417e-81f5-8fe6f9a4fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "# uncomment & execute the following line to see how the embedding layer weights look like\n",
    "# print(pos_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c369a1e7-d566-4b53-b398-d6adafb44105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "\n",
    "# uncomment & execute the following line to see how the embeddings look like\n",
    "# print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e9d9f-2935-461a-9518-6d1386b976d6",
   "metadata": {},
   "source": [
    "- Tính `input_embeddings = token_embeddings + pos_embeddings`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b22fab89-526e-43c8-9035-5b7018e34288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n",
    "\n",
    "# uncomment & execute the following line to see how the embeddings look like\n",
    "# print(input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb0f7e-460d-44db-b366-096adcd84fff",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/19.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63230f2e-258f-4497-9e2e-8deee4530364",
   "metadata": {},
   "source": [
    "# Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3293a6-45a5-47cd-aa00-b23e3ca0a73f",
   "metadata": {},
   "source": [
    "[./dataloader.ipynb](./dataloader.ipynb) chứa code hoàn chỉnh từ bài này\n",
    "\n",
    "Đáp án bài tập trong sách [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "\n",
    "Sâu hơn về [Byte Pair Encoding (BPE) Tokenizer From Scratch](../02_bonus_bytepair-encoder/compare-bpe-tiktoken.ipynb) coi ở đây."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
