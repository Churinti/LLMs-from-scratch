# 第三章 编码的注意力机制
## 3.1 注意力机制的基本概念
- 注意力机制是一种模仿人类注意力的机制
### 长序列建模中的问题
- RNN是在Transformer之前的主流模型
    - RNN是一种将前序步骤的输出作为输入的神经网络模型，文本是一种序列数据
    - 编码器逐次更新隐藏状态，并把最终的隐藏状态传递给解码器
    - 解码器逐次更新隐藏状态，并把最终的隐藏状态传递给输出层
    - RNN的每一步都依赖于前一步的输出
    - 编码器每一步都会更其隐藏状态，但这会导致每次试图在最后的隐藏层中捕获全部的含义，解码器也是类似，每一步更新，预测下一个词
- RNN在处理长序列时会遇到梯度消失和梯度爆炸的问题
    1. RNN在处理长序列时会遇到信息遗忘的问题
    2. 解码阶段，无法直接访问解码器中的早期状态
## 3.2 使用注意力机制捕捉数据依赖关系
### Bahdanan 注意力机制
- 解码器可以在每个解码步骤选择性访问输入序列中的不同部分
- 注意力机制是一种模仿人类注意力的机制,有点类似于人类在阅读时候的注意力可能除了当前聚焦的单词外，还会关注前面的词，抽出重点 (注：应该就是对于不同词的注意力权重不同)

