# 第三章 编码的注意力机制
## 3.1 注意力机制的基本概念
- 注意力机制是一种模仿人类注意力的机制
### 长序列建模中的问题
- RNN是在Transformer之前的主流模型
    - RNN是一种将前序步骤的输出作为输入的神经网络模型，文本是一种序列数据
    - 编码器逐次更新隐藏状态，并把最终的隐藏状态传递给解码器
    - 解码器逐次更新隐藏状态，并把最终的隐藏状态传递给输出层
    - RNN的每一步都依赖于前一步的输出
    - 编码器每一步都会更其隐藏状态，但这会导致每次试图在最后的隐藏层中捕获全部的含义，解码器也是类似，每一步更新，预测下一个词
- RNN在处理长序列时会遇到梯度消失和梯度爆炸的问题
    1. RNN在处理长序列时会遇到信息遗忘的问题
    2. 解码阶段，无法直接访问解码器中的早期状态
## 3.2 使用注意力机制捕捉数据依赖关系
### Bahdanan 注意力机制
- 解码器可以在每个解码步骤选择性访问输入序列中的不同部分
- 注意力机制是一种模仿人类注意力的机制,有点类似于人类在阅读时候的注意力可能除了当前聚焦的单词外，还会关注前面的词，抽出重点 (注：应该就是对于不同词的注意力权重不同)

## 3.3 通过自注意力机制关注输入的不同部分
>自注意力机制中，‘自’指的是通过关联`单个`输入中的不同位置来计算注意力权重的能力
>而传统的注意力机制关注的是`不同`输入之间的关系

### 3.3.1 无可训练权重的简单自注意力机制
- 假设我们有输入词元x^(1), x^(2), ..., x^(6), dim=3
```python
import torch

inputs = torch.tensor(
  [[0.43, 0.15, 0.89], # Your     (x^1)
   [0.55, 0.87, 0.66], # journey  (x^2)
   [0.57, 0.85, 0.64], # starts   (x^3)
   [0.22, 0.58, 0.33], # with     (x^4)
   [0.77, 0.25, 0.10], # one      (x^5)
   [0.05, 0.80, 0.55]] # step     (x^6)
)
```

- 通过计算输入序列中每个位置的加权平均值来捕捉输入序列中不同位置之间的关系
- 自注意力权重计算完后，是一个`n*n`的矩阵a，n是输入序列的长度，每一行代表一个词的注意力权重
![](./images/3.3.png)
- 序列中两两之间是通过嵌入向量的相乘得出(注：这里的嵌入向量是指每个词的向量表示,结果也没有被归一化)
- 通过softmax函数将注意力权重归一化为概率分布 (注：实际中会使用torch.softmax_naive来计算，确保每一行的和为1，即在所有维度的和为100%)
- 以上就是矩阵中的每个元素的计算方式

#### 上下文向量z
>定义是嵌入的输入词元x^(i)与他自己对应的注意力权重a^(i)的加权平均
>```python
>z^(i) = sum(a^(i,j) * x^(j)) for j in range(n)
>=>z^(i) = a^(i,1) * x^(1) + a^(i,2) * x^(2) + ... + a^(i,n) * x^(n)
> z^(2) = a^(2,1) * x^(1) + a^(2,2) * x^(2) + ... + a^(2,n) * x^(n)
> z^(2) = 0.13 * x^(1) + 0.23 * x^(2) + ... + 0.15 * x^(6)
>```
>每个词元的上下文向量z^(i)是一个加权平均值，包含了每个序列中词元的注意力权重

